# Speech Emotion Recognition

## Overview

This project implements a Speech Emotion Recognition (SER) model using MLP, CNN and Long Short-Term Memory (LSTM) models. The model processes audio data to classify emotions based on the extracted features from the audio signals.

## Table of Contents

- [Features](#features)
- [Technologies Used](#technologies-used)
- [Dataset](#dataset)
- [Installation](#installation)

## Features

- Emotion recognition from audio files.
- Gender classification based on speech.
- Data preprocessing using MFCC (Mel-frequency cepstral coefficients) & Spectrogram.
- Visualization of training history (loss and accuracy).

## Technologies Used

- Python
- TensorFlow
- Keras
- Librosa
- NumPy
- Matplotlib
- Scikit-learn

## Dataset

The dataset used in this project is the [Speech Emotion Recognition dataset](https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio) which contains various audio samples categorized by emotion and gender.

## Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/Rupesh-KMeena/speech_emotion_recognition.git
   cd speech-emotion-recognition
